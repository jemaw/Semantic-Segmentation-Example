{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import transform as stransform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import unet_parts_torch as u_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "IMAGE_FOLDER = './images'\n",
    "MASK_FOLDER = './masks'\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 6\n",
    "OUTPUT_DIR = './output'\n",
    "KERNEL_NUM = 12\n",
    "SEED = 42\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NucleiDataset(Dataset):\n",
    "    \"\"\"Dataset for semantic segmentation\n",
    "    https://data.broadinstitute.org/bbbc/BBBC038/\"\"\"\n",
    "    def __init__(self, id_lst, images_folder, masks_folder, transformer=None):\n",
    "        self.id_lst = id_lst\n",
    "        self.images_folder = images_folder\n",
    "        self.masks_folder = masks_folder\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id_lst)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = self.id_lst[idx]\n",
    "        img_path = os.path.join(self.images_folder, img_idx + '.png')\n",
    "        mask_path = os.path.join(self.masks_folder, img_idx + '_mask.png')\n",
    "        image = io.imread(img_path, as_gray=True)\n",
    "        mask = io.imread(mask_path, as_gray=True)\n",
    "        sample = {'image': image, \n",
    "                  'mask': mask}\n",
    "        \n",
    "        if self.transformer:\n",
    "            sample = self.transformer(sample)\n",
    "            \n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob(os.path.join(IMAGE_FOLDER, '*.png'))\n",
    "ids = [os.path.splitext(os.path.basename(x))[0] for x in all_images]\n",
    "# show some ids\n",
    "ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TransformerEval(object):\n",
    "    def __init__(self):\n",
    "        self.image_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "        image = stransform.resize(image, self.image_shape, mode='constant', anti_aliasing=True)\n",
    "        mask = stransform.resize(mask, self.image_shape, mode='constant', anti_aliasing=True)\n",
    "        \n",
    "        \n",
    "        image = np.expand_dims(image, -1).astype(np.float32)\n",
    "        mask = np.expand_dims(mask, -1).astype(np.float32)\n",
    "        image = image.transpose((2,0,1))\n",
    "        mask = mask.transpose((2,0,1))\n",
    "        return {'image': torch.from_numpy(image.copy()),\n",
    "               'mask': torch.from_numpy(mask.copy())}\n",
    "    \n",
    "class TransformerTrain(object):\n",
    "    def __init__(self):\n",
    "        self.image_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "        image = stransform.resize(image, self.image_shape, mode='constant', anti_aliasing=True)\n",
    "        mask = stransform.resize(mask, self.image_shape, mode='constant', anti_aliasing=True)\n",
    "        \n",
    "        if np.random.binomial(1, 0.5):\n",
    "            image = np.fliplr(image)\n",
    "            mask = np.fliplr(mask)\n",
    "        if np.random.binomial(1, 0.5):\n",
    "            image = np.flipud(image)\n",
    "            mask = np.flipud(mask)\n",
    "        if np.random.binomial(1, 0.5):\n",
    "            degree = np.random.randint(-180, 180)\n",
    "            image = stransform.rotate(image, degree, mode='constant')\n",
    "            mask = stransform.rotate(mask, degree, mode='constant')\n",
    "       \n",
    "        image = np.expand_dims(image, -1).astype(np.float32)\n",
    "        mask = np.expand_dims(mask, -1).astype(np.float32)\n",
    "        image = image.transpose((2,0,1))\n",
    "        mask = mask.transpose((2,0,1))\n",
    "        \n",
    "        return {'image': torch.from_numpy(image.copy()),\n",
    "               'mask': torch.from_numpy(mask.copy())} # we somehow need copy, else it fails\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, eval_ids = train_test_split(ids, random_state=SEED)\n",
    "print('Trainids length: ', len(train_ids))\n",
    "print('Eval length: ', len(eval_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = NucleiDataset(train_ids, IMAGE_FOLDER, MASK_FOLDER, TransformerTrain())\n",
    "ds_eval = NucleiDataset(eval_ids, IMAGE_FOLDER, MASK_FOLDER, TransformerEval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dataloader_eval = DataLoader(ds_eval, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "\n",
    "#for i_batch, sample_batched in enumerate(dataloader_train):\n",
    "#    print(i_batch, sample_batched['image'].shape, sample_batched['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        k = KERNEL_NUM\n",
    "        output_channels = 1\n",
    "        input_channels = 1\n",
    "        conv_op = u_parts.double_conv\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.inc = u_parts.inconv(input_channels, k, conv_op)\n",
    "        self.down1 = u_parts.down(k, 2*k, conv_op)\n",
    "        self.down2 = u_parts.down(2*k, 4*k, conv_op)\n",
    "        self.down3 = u_parts.down(4*k, 8*k, conv_op)\n",
    "        self.down4 = u_parts.down(8*k, 8*k, conv_op)\n",
    "        \n",
    "        self.up1 = u_parts.up(2*8*k, 4*k, conv_op)\n",
    "        self.up2 = u_parts.up(2*4*k, 2*k, conv_op)\n",
    "        self.up3 = u_parts.up(2*2*k, k, conv_op)\n",
    "        self.up4 = u_parts.up(2*k, k, conv_op)\n",
    "        self.outc = u_parts.outconv(k, output_channels)\n",
    "        \n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sampled_batch in enumerate(loader):\n",
    "       \n",
    "        image = sampled_batch['image']\n",
    "        mask = sampled_batch['mask']\n",
    "        #print(image.shape, mask.shape)\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        mask_pred = torch.sigmoid(output)\n",
    "        #print('Mask pred shape', mask_pred.shape)\n",
    "        #print('Mask shape', mask.shape)\n",
    "        #loss = nn.BCELoss(mask, mask_pred)\n",
    "        loss = F.binary_cross_entropy(mask_pred, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(image), len(loader.dataset),\n",
    "                    100. * batch_idx / len(loader), loss.item()))\n",
    "       \n",
    "    \n",
    "def dice_pyt(prediction, label):\n",
    "    # TODO should mean dice over batch\n",
    "    prediction = torch.round(prediction)\n",
    "    label = torch.round(label)\n",
    "    intersection = prediction*label\n",
    "    return 2*torch.sum(intersection)/(torch.sum(prediction) + torch.sum(label))\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    model.eval()\n",
    "    dice = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for sampled_batch in loader:\n",
    "            cnt += 1\n",
    "            image = sampled_batch['image']\n",
    "            mask = sampled_batch['mask']\n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "            output =  model(image)\n",
    "            mask_pred = torch.sigmoid(output)\n",
    "            dice += dice_pyt(mask_pred, mask)\n",
    "            \n",
    "            # visualization could also be done with tensorboardX \n",
    "            # https://github.com/lanpa/tensorboardX\n",
    "            if cnt % 10 == 0:\n",
    "                image = image.cpu().data.numpy()[0][0]\n",
    "                mask = mask.cpu().data.numpy()[0][0]\n",
    "                mask_pred = mask_pred.cpu().data.numpy()[0][0]\n",
    "                merge = np.hstack([image, mask, mask_pred])\n",
    "                io.imsave('progress.png', merge)\n",
    "        dice/=cnt\n",
    "        print('Test Dice: ', dice)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "model = Unet().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, device, dataloader_train, optimizer, epoch)\n",
    "    evaluate(model, device, dataloader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
